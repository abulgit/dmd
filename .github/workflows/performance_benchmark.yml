name: Performance Benchmark

on:
  pull_request:
    branches: [ master ]
    paths:
      - 'compiler/**'
      - '.github/workflows/performance_benchmark.yml'

jobs:
  benchmark:
    name: DMD Performance Benchmark
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout PR Branch
      uses: actions/checkout@v3
      with:
        path: dmdbranch
        
    - name: Checkout master branch
      uses: actions/checkout@v3
      with:
        ref: master
        path: dmdmaster
        
    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y gcc g++ gdb time
        
        # Install Hyperfine for better benchmarking
        wget https://github.com/sharkdp/hyperfine/releases/download/v1.16.1/hyperfine_1.16.1_amd64.deb
        sudo dpkg -i hyperfine_1.16.1_amd64.deb
        
    - name: Setup D compiler
      uses: dlang-community/setup-dlang@v1
      with:
        compiler: dmd-latest
        
    - name: Build master DMD
      working-directory: dmdmaster
      run: |
        make -f posix.mak -j2 AUTO_BOOTSTRAP=1
        
    - name: Build PR DMD
      working-directory: dmdbranch
      run: |
        make -f posix.mak -j2 AUTO_BOOTSTRAP=1
        
    - name: Create benchmark script
      working-directory: dmdbranch
      run: |
        cat > perf_benchmark.d << 'EOL'
        #!/usr/bin/env rdmd
        /**
         * Performance Regression Benchmark for DMD
         * 
         * This script runs benchmarks on DMD to measure compilation performance metrics
         * using Hyperfine for statistical accuracy.
         * It compares a baseline DMD (typically master) with a modified DMD.
         */
        import std.stdio;
        import std.process;
        import std.array;
        import std.conv;
        import std.string;
        import std.datetime;
        import std.file;
        import std.algorithm;
        import std.math;
        import std.json;

        struct BenchmarkResult
        {
            double compileSecs;
            size_t memoryMB;
            string command;
            double stdDev;    // Standard deviation for multiple runs
            double min;       // Minimum time across runs
            double max;       // Maximum time across runs
        }

        BenchmarkResult runBenchmark(string dmdPath, string testCase)
        {
            BenchmarkResult result;
            
            // Capture the command for reference
            result.command = dmdPath ~ " " ~ testCase;
            
            // Hyperfine benchmarks with 3 warmup runs and 5 timed runs
            // The --export-json option captures all measurements
            string jsonFile = (dmdPath.canFind("master") ? "baseline" : "modified") ~ "_results.json";
            auto hyperfineCmd = "hyperfine --warmup 3 --runs 5 --export-json " ~ jsonFile 
                              ~ " --command-name " ~ (dmdPath.canFind("master") ? "baseline" : "modified")
                              ~ " '" ~ dmdPath ~ " " ~ testCase ~ "'";
            
            writeln("Running: ", hyperfineCmd);
            executeShell(hyperfineCmd);
            
            // Parse the hyperfine JSON output
            if (std.file.exists(jsonFile))
            {
                string jsonContent = std.file.readText(jsonFile);
                JSONValue json = parseJSON(jsonContent);
                
                // Extract mean time
                result.compileSecs = json["results"][0]["mean"].floating;
                
                // Extract standard deviation
                result.stdDev = json["results"][0]["stddev"].floating;
                
                // Extract min/max times
                result.min = json["results"][0]["min"].floating;
                result.max = json["results"][0]["max"].floating;
            }
            
            // Also capture memory usage with time command
            // Since hyperfine doesn't track memory usage
            auto timeCmd = "time -v " ~ dmdPath ~ " " ~ testCase ~ " 2>&1";
            auto output = executeShell(timeCmd).output.splitLines();
            
            // Extract memory usage from time output
            foreach (line; output)
            {
                if (line.canFind("Maximum resident set size (kbytes):"))
                    result.memoryMB = line.split(":")[1].strip().to!size_t / 1024;
            }
            
            return result;
        }

        string formatResult(BenchmarkResult result)
        {
            return format("Compile time: %.3f seconds (Â±%.3f) | Min: %.3f s | Max: %.3f s | Memory: %d MB", 
                        result.compileSecs, result.stdDev, result.min, result.max, result.memoryMB);
        }

        string formatComparison(BenchmarkResult baseline, BenchmarkResult modified)
        {
            double timeDiff = modified.compileSecs - baseline.compileSecs;
            double timePercent = baseline.compileSecs > 0 ? (timeDiff / baseline.compileSecs) * 100 : 0;
            
            double memDiff = modified.memoryMB - baseline.memoryMB;
            double memPercent = baseline.memoryMB > 0 ? (memDiff / baseline.memoryMB) * 100 : 0;
            
            return format("Time: %+.3f seconds (%+.2f%%) | Memory: %+d MB (%+.2f%%)",
                        timeDiff, timePercent, cast(int)memDiff, memPercent);
        }

        // Safe percentage calculation that avoids division by zero
        double safePercentage(double diff, double baseline)
        {
            if (baseline == 0 || isNaN(baseline))
                return 0.0;
            return (diff / baseline) * 100;
        }

        void main(string[] args)
        {
            if (args.length < 4)
            {
                writeln("Usage: ./perf_benchmark.d <baseline_dmd> <modified_dmd> <test_case>");
                writeln("Example: ./perf_benchmark.d ./dmdmaster/dmd ./dmdbranch/dmd '-i=std -c -unittest -version=StdUnittest -preview=dip1000 phobos/std/package.d'");
                return;
            }
            
            string baselineDmd = args[1];
            string modifiedDmd = args[2];
            string testCase = args[3];
            
            writeln("Running benchmark with:");
            writeln("  Baseline DMD: ", baselineDmd);
            writeln("  Modified DMD: ", modifiedDmd);
            writeln("  Test case: ", testCase);
            writeln();
            
            // Run benchmarks
            writeln("Running baseline benchmark...");
            auto baselineResult = runBenchmark(baselineDmd, testCase);
            
            writeln("\nRunning modified benchmark...");
            auto modifiedResult = runBenchmark(modifiedDmd, testCase);
            
            // Report results
            writeln("\n=== BENCHMARK RESULTS ===");
            writeln("Baseline: ", formatResult(baselineResult));
            writeln("Modified: ", formatResult(modifiedResult));
            writeln("\nDifference: ", formatComparison(baselineResult, modifiedResult));
            
            // Calculate differences
            double timeDiff = modifiedResult.compileSecs - baselineResult.compileSecs;
            double timePercent = safePercentage(timeDiff, baselineResult.compileSecs);
            double memDiff = modifiedResult.memoryMB - baselineResult.memoryMB;
            double memoryPercent = safePercentage(memDiff, baselineResult.memoryMB);
            
            // Generate JSON manually to ensure compatibility
            string json = "{\n";
            json ~= `  "baseline": {` ~ "\n";
            json ~= `    "time": ` ~ baselineResult.compileSecs.to!string ~ ",\n";
            json ~= `    "memory": ` ~ baselineResult.memoryMB.to!string ~ ",\n";
            json ~= `    "command": "` ~ baselineResult.command ~ `",` ~ "\n";
            json ~= `    "stddev": ` ~ baselineResult.stdDev.to!string ~ ",\n";
            json ~= `    "min": ` ~ baselineResult.min.to!string ~ ",\n";
            json ~= `    "max": ` ~ baselineResult.max.to!string ~ "\n";
            json ~= "  },\n";
            json ~= `  "modified": {` ~ "\n";
            json ~= `    "time": ` ~ modifiedResult.compileSecs.to!string ~ ",\n";
            json ~= `    "memory": ` ~ modifiedResult.memoryMB.to!string ~ ",\n";
            json ~= `    "command": "` ~ modifiedResult.command ~ `",` ~ "\n";
            json ~= `    "stddev": ` ~ modifiedResult.stdDev.to!string ~ ",\n";
            json ~= `    "min": ` ~ modifiedResult.min.to!string ~ ",\n";
            json ~= `    "max": ` ~ modifiedResult.max.to!string ~ "\n";
            json ~= "  },\n";
            json ~= `  "diff": {` ~ "\n";
            json ~= `    "time": ` ~ timeDiff.to!string ~ ",\n";
            json ~= `    "timePercent": ` ~ timePercent.to!string ~ ",\n";
            json ~= `    "memory": ` ~ memDiff.to!string ~ ",\n";
            json ~= `    "memoryPercent": ` ~ memoryPercent.to!string ~ "\n";
            json ~= "  }\n";
            json ~= "}\n";
            
            // Write JSON to file for GitHub Actions
            std.file.write("benchmark_results.json", json);
            writeln("\nJSON results saved to benchmark_results.json");
        }
        EOL
        chmod +x perf_benchmark.d
        
    - name: Create Complex Test Case
      run: |
        # Create a complex test file that heavily uses deprecated features
        cat > complex_test.d << 'EOL'
        module complex_test;
        
        import std.stdio;
        import std.conv;
        import std.array;
        
        // Create many deprecated symbols to trigger the checkDeprecated method
        deprecated("Use newFunction1 instead") void oldFunction1() { }
        deprecated("Use newFunction2 instead") void oldFunction2() { }
        deprecated("Use newFunction3 instead") void oldFunction3() { }
        deprecated("Use newFunction4 instead") void oldFunction4() { }
        deprecated("Use newFunction5 instead") void oldFunction5() { }
        deprecated("Use newFunction6 instead") void oldFunction6() { }
        deprecated("Use newFunction7 instead") void oldFunction7() { }
        deprecated("Use newFunction8 instead") void oldFunction8() { }
        deprecated("Use newFunction9 instead") void oldFunction9() { }
        deprecated("Use newFunction10 instead") void oldFunction10() { }
        
        // Create a complex class hierarchy with deprecated methods
        class BaseClass {
            deprecated("Use newMethod instead") void oldMethod() { }
        }
        
        class DerivedClass1 : BaseClass {
            deprecated override void oldMethod() { }
        }
        
        class DerivedClass2 : DerivedClass1 {
            deprecated override void oldMethod() { }
        }
        
        // Create a deprecated struct with many fields
        deprecated struct OldStruct {
            int field1, field2, field3, field4, field5;
            string name;
            double value;
            
            deprecated this(int f1, int f2, int f3, int f4, int f5) {
                field1 = f1;
                field2 = f2;
                field3 = f3;
                field4 = f4;
                field5 = f5;
            }
            
            deprecated void calculate() {
                // Some complex calculations
                for (int i = 0; i < 100; i++) {
                    value += (field1 * field2) / (field3 + field4 - field5);
                }
            }
        }
        
        // Create a complex function that uses all these deprecated elements
        void complexFunction() {
            // Call all deprecated functions
            oldFunction1();
            oldFunction2();
            oldFunction3();
            oldFunction4();
            oldFunction5();
            oldFunction6();
            oldFunction7();
            oldFunction8();
            oldFunction9();
            oldFunction10();
            
            // Create and use deprecated class hierarchy
            auto base = new BaseClass();
            base.oldMethod();
            
            auto derived1 = new DerivedClass1();
            derived1.oldMethod();
            
            auto derived2 = new DerivedClass2();
            derived2.oldMethod();
            
            // Create and use deprecated struct
            OldStruct s = OldStruct(1, 2, 3, 4, 5);
            s.name = "test";
            s.calculate();
        }
        
        // Main function with a loop to make it process-intensive
        void main() {
            for (int i = 0; i < 5; i++) {
                complexFunction();
            }
        }
        EOL
        
    - name: Run Performance Benchmark
      id: benchmark
      run: |
        # Create a small test file
        echo 'void main() { foreach(i; 0..1000) { int x = i*i; } }' > test.d
        
        # Run benchmark on our complex test case (should trigger inefficiencies)
        echo "Running benchmark on complex test with plenty of deprecated symbols..."
        ./dmdbranch/perf_benchmark.d ./dmdmaster/compiler/generated/linux/release/64/dmd ./dmdbranch/compiler/generated/linux/release/64/dmd "complex_test.d -vcolumns"
        
        # Show compilation output for debugging
        echo "Testing if both compilers can compile the test case correctly..."
        ./dmdmaster/compiler/generated/linux/release/64/dmd complex_test.d -vcolumns || true
        ./dmdbranch/compiler/generated/linux/release/64/dmd complex_test.d -vcolumns || true
        
        # Store the results for the comment
        RESULTS=$(cat benchmark_results.json)
        echo "results<<EOF" >> $GITHUB_OUTPUT
        echo "$RESULTS" >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT
        
    - name: Post Benchmark Results
      uses: actions/github-script@v6
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const results = JSON.parse(`${{ steps.benchmark.outputs.results }}`);
          
          // Format the comment
          const baselineTime = parseFloat(results.baseline.time).toFixed(3);
          const modifiedTime = parseFloat(results.modified.time).toFixed(3);
          const timeDiff = parseFloat(results.diff.time).toFixed(3);
          const timePercent = parseFloat(results.diff.timePercent).toFixed(2);
          
          const baselineMemory = Math.round(results.baseline.memory);
          const modifiedMemory = Math.round(results.modified.memory);
          const memoryDiff = Math.round(results.diff.memory);
          const memoryPercent = parseFloat(results.diff.memoryPercent).toFixed(2);
          
          // Standard deviation for statistical significance
          const baselineStdDev = parseFloat(results.baseline.stddev).toFixed(3);
          const modifiedStdDev = parseFloat(results.modified.stddev).toFixed(3);
          
          // Min/Max values for ranges
          const baselineMin = parseFloat(results.baseline.min).toFixed(3);
          const baselineMax = parseFloat(results.baseline.max).toFixed(3);
          const modifiedMin = parseFloat(results.modified.min).toFixed(3);
          const modifiedMax = parseFloat(results.modified.max).toFixed(3);
          
          // Create emoji indicators
          const timeEmoji = (results.diff.timePercent <= 0) ? 'ð¢' : 'ð´';
          const memoryEmoji = (results.diff.memoryPercent <= 0) ? 'ð¢' : 'ð´';
          
          // Determine if the difference is statistically significant
          // Using a simple overlap test: if the ranges (meanÂ±stddev) don't overlap, it's significant
          const baselineUpper = parseFloat(results.baseline.time) + parseFloat(results.baseline.stddev);
          const baselineLower = parseFloat(results.baseline.time) - parseFloat(results.baseline.stddev);
          const modifiedUpper = parseFloat(results.modified.time) + parseFloat(results.modified.stddev);
          const modifiedLower = parseFloat(results.modified.time) - parseFloat(results.modified.stddev);
          
          const isSignificant = (baselineUpper < modifiedLower) || (modifiedUpper < baselineLower);
          const significanceIndicator = isSignificant ? '**Statistically Significant**' : 'Not statistically significant';
          
          // Create the comment body
          let comment = '## DMD Performance Benchmark Results\n\n';
          comment += `### Compilation Time\n${timeEmoji} **${timePercent}%** change *(${baselineTime}s â ${modifiedTime}s, diff: ${timeDiff}s)* - ${significanceIndicator}\n\n`;
          comment += `**Baseline:** ${baselineTime}s Â±${baselineStdDev}s (range: ${baselineMin}s - ${baselineMax}s)\n`;
          comment += `**Modified:** ${modifiedTime}s Â±${modifiedStdDev}s (range: ${modifiedMin}s - ${modifiedMax}s)\n\n`;
          comment += `### Memory Usage\n${memoryEmoji} **${memoryPercent}%** change *(${baselineMemory}MB â ${modifiedMemory}MB, diff: ${memoryDiff}MB)*\n\n`;
          comment += `*Benchmark test: \`${results.baseline.command}\`*\n\n`;
          comment += `*Benchmarked with [Hyperfine](https://github.com/sharkdp/hyperfine): 3 warmup runs, 5 measured runs*`;
          
          // Post comment to PR
          const { owner, repo } = context.repo;
          const issue_number = context.issue.number;
          
          await github.rest.issues.createComment({
            owner,
            repo,
            issue_number,
            body: comment
          }); 